# ğŸ§  Hackathon Big Data & AI  
## Challenge Ufficiale ğŸš€  
**"F1 Social Analytics Engine: estrazione, integrazione e sentiment analysis dal GP di Monaco 2025"**

---
## Indice

- [ğŸ Obiettivo](#-obiettivo)
- [ğŸ“¥ Fase 1 â€” Data Ingestion and Dataset Building](#-fase-1---data-ingestion-and-dataset-building)
    - [ğŸ“‡ Schema dataset finale](#-schema-dataset-finale)
- [ğŸ“¥ Fase 2 â€” Social Analysis](#-fase-2---social-analysis)
    - [ğŸ¯ Obiettivo della parte di Social Analysis](#-obiettivo-della-parte-di-social-analysis)
    - [âœ¨ Bonus: Estensione LLM-based - Creazione automatica dei report](#-bonus-estensione-llm-based---generatione-automatica-dei-report)
- [ğŸ“¦ ModalitÃ  di consegna](#-modalitÃ -di-consegna)
- [ğŸ“œ Metriche di Valutazione e Punteggi](#-metriche-di-valutazione-e-punteggi)
- [1ï¸âƒ£ Inizializzazione progetto](#-inizializzazione-progetto)
- [ğŸ•’ Timeline](#-timeline)

---

## ğŸ Obiettivo 

In occasione del Gran Premio di Monaco 2025, uno degli eventi piÃ¹ iconici e seguiti della Formula 1, il vostro compito Ã¨ progettare e realizzare un sistema intelligente che recupera, integra e analizza post e commenti provenienti dai social media, per comprendere come gli utenti vivono lâ€™evento prima, durante e dopo la gara.

L'obiettivo Ã¨ cogliere le emozioni, le opinioni e le reazioni degli appassionati di motori sparsi in tutto il mondo, offrendo un quadro dinamico e aggiornato in tempo reale su come il pubblico percepisce i piloti, le scuderie, i momenti salienti e gli episodi controversi della gara. SarÃ  anche importante profilare il tipo di spettatori e/o di appassionati dell'evento estraendo caratteristiche comuni a gruppi di utenti simili.

Questa sfida ha due anime principali:

- **Data ingestion & dataset building (fondamentale!)**
- **Social analysis avanzata (con o senza LLM)**

---


## ğŸ“¥ Fase 1 - Data Ingestion and Dataset Building

Progettare e implementare una pipeline di data ingestion che:

- ğŸ” Recupera in modo automatico (o semi-automatico) contenuti testuali da diversi social media: Instagram, Facebook, Twitter/X, Reddit, YouTube (ma anche altri non in lista che pensate possano essere significativi). (Le analisi cross-platform sono ben gradite ğŸ¤—)

- ğŸ§¹ Pulisce, filtra e normalizza i dati testuali, le interazioni e i metadati.

- ğŸ“¦ Produce un dataset finale conforme a uno schema comune condiviso da tutti i gruppi (vedi sotto).


ğŸ“œ NOTA
- _Il linguaggio ufficiale Ã¨ l'Inglese ovviamente, ma i piÃ¹ coraggiosi possono provare a fare analisi multilingua (gestendo anche il Francese ad esempio)_

---

### ğŸ“‡ Schema dataset finale:

Di seguito lo schema che dovrÃ  seguire il Dataset ottenuto a valle della prima fase.

| Feature           | Descrizione                                                                 | Datatype             | Nullable | Note                                        | Esempio                  |
|-------------------|-----------------------------------------------------------------------------|----------------------|----------|---------------------------------------------|--------------------------|
| content_id        | ID univoco del post o commento                                              | stringa              | No       | es. ID nativo social o hash generato        | fb_post_001              |
| observation_time  | Timestamp di unâ€™osservazione di uno specifico contenuto                     | datetime (ISO 8601)  | No       | formato: YYYY-MM-DDTHH:MM:SSZ                | 2025-05-15T10:00:00Z     |
| user              | ID o nome utente (anonimizzato se necessario)                              | stringa              | No       |                                             | giulia_snap              |
| user_location     | CittÃ /Stato indicati nel profilo dellâ€™utente (se presente)                  | stringa              | Si       |                                             | Nizza                    |
| social_media      | Nome della piattaforma (es. Twitter, Reddit, etc.)                          | stringa              | No       |                                             | Instagram                |
| publish_date      | Timestamp UTC del post/commento                                             | datetime (ISO 8601)  | No       | formato: YYYY-MM-DDTHH:MM:SSZ                | 2025-05-25T19:45:10Z     |
| geo_location      | Coordinate GPS (latitudine, longitudine) del luogo dellâ€™interazione         | tuple(float, float)  | Si       |                                             | (45.4642, 9.1900)        |
| comment_raw_text  | Testo originale del contenuto                                               | stringa              | No       | Se non câ€™Ã¨ testo, mettere stringa vuota ""  | Corsa Pazzesca ğŸ˜¬ğŸï¸       |
| emoji             | Emoji utilizzate nel testo                                                  | Lista[stringa]       | Si       |                                             | ğŸ˜¬ğŸï¸                      |
| reference_post_url| Link al post originale (se Ã¨ una risposta/commento)                        | stringa              | Si       | Deve essere un URL                           | facebook.com/post/123456789 |
| like_count        | Numero di like/upvote                                                       | Intero               | No       | Default 0, non puÃ² essere negativo          | 112                      |
| reply_count       | Numero di commenti/risposte ricevute                                       | Intero               | No       | Default 0, non puÃ² essere negativo          | 17                       |
| repost_count      | Numero di condivisioni/retweet                                             | Intero               | No       | Default 0, non puÃ² essere negativo          | 1                        |
| quote_count       | Quote tweet o repost con commento (se disponibile)                         | Intero               | No       | Default 0, non puÃ² essere negativo          | 0                        |
| bookmark_count    | Numero di salvataggi (se disponibile)                                     | Intero               | No       | Default 0, non puÃ² essere negativo          | 0                        |
| content_type      | Tipo di contenuto analizzato                                               | stringa              | No       | Valore categorico: "post" o "commento"      | post                     |


ğŸ“œ NOTA
_E' importante che tutti i dataset rispettino la convenzione riportata sopra, i dataset che non rispettano lo schema saranno penalizzati in fase di valutazione_

---

## ğŸ“¥ Fase 2 - Social Analysis

Una volta creato un dataset coerente, la sfida si sposta sull'analisi dei risultati. Ecco cosa includere, come strutturare la consegna e cosa valutare.

### ğŸ¯ Obiettivo della Social Analysis

Analizzare i contenuti raccolti (post/commenti) per comprendere come evolve lâ€™umore e la percezione degli utenti nel tempo e nello spazio in relazione al Gran Premio di Monaco 2025, con un focus sulle fasi prima, durante e dopo la gara. Oltretutto raccogliendo le informazioni degli utenti sarÃ  possibile anche definirne i profili e le caratteristiche comuni.

Lâ€™analisi puÃ² mettere in luce emozioni, attese, reazioni e controversie legate ai piloti, ai team e possibili correlazioni con gli eventi chiave della gara. Sono quindi suggerite tecniche di Sentiment Analysis,
Emotion Analysis, hate speech recognition, ma anche virality pattern recognition, misinformation detection etc.

---

#### âš™ï¸ Approcci suggeriti

#### 1. Approccio classico (NLP tradizionale)

Utilizzo di tecniche di Natural Language Processing tradizionali, quali:  
- Pre-elaborazione del testo (tokenizzazione, rimozione stopwords, stemming)  
- Rappresentazione con tecniche tipo TF-IDF  
- Classificatori supervisionati (SVM, Naive Bayes, Random Forest)  
- Analizzatori di sentiment giÃ  pronti come TextBlob o VAD  

#### 2. Approccio con LLM (Large Language Models)

Sfruttare modelli linguistici di nuova generazione (GPT, LLaMA, Claude, Mistral, ecc.) per:  
- Classificare direttamente il sentiment di ogni contenuto  
- Estendere lâ€™analisi con rilevazione di emozioni, argomenti principali, intensitÃ  del sentimento  
- Arricchire dati mancanti (es. dedurre location, riconoscere sarcasmo, ecc.)  

Questi modelli possono essere interrogati tramite prompt ben costruiti per analisi dettagliate su testi brevi, rumorosi o ambigui.

### Alcuni riferimenti utili:

- Emotion recognition
â https://huggingface.co/SamLowe/roberta-base-go_emotions
â â https://huggingface.co/j-hartmann/emotion-english-distilroberta-base

- Hate Speech Recognition
https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target

- Sentiment
https://huggingface.co/tabularisai/multilingual-sentiment-analysis

---

### âœ¨ Bonus: Estensione LLM-based - Generatione automatica dei report

Oltre alla social analysis, Ã¨ incoraggiato lâ€™uso di LLM e modelli multimodali per:  

- ğŸ“Š Generare automaticamente grafici o visualizzazioni dai dati analizzati  
- ğŸ§  Riassumere in linguaggio naturale i risultati (es. "Nei commenti dalla Francia, il sentiment era positivo prima della gara, ma Ã¨ calato dopo lâ€™incidente al 35Â° giro")  

Insomma, la generazione del report finale potrebbe essere eseguita da modelli di Generative AI.

Esempi di strumenti/approcci:  
- GPT-4-Vision, Gemini, Claude 3 per generare visualizzazioni via prompt  
- Plotly + LLM per generare codice Python per grafici  
- Diagrammi, mappe e infografiche sintetiche generate da modelli come DALLÂ·E o Midjourney 


**âš ï¸ Questa parte Ã¨ opzionale ma valorizzata nella valutazione, dimostrando originalitÃ  e padronanza delle tecnologie LLM.**

---

## ğŸ“¦ ModalitÃ  di consegna

Lista degli artefatti da consegnare:

- Codice sorgente su Repository GitHub + pacchetti necessari (file requirements.txt) + eventuale Documentazione tecnica (link da condividere con gli organizzatori prima della scadenza)
- Dataset generato dallâ€™ingestion (**)
- Documento PDF, Presentazione Powerpoint o qualsiasi altro formato con risultati analisi dellâ€™evento (inclusi eventuali grafici Bonus) allâ€™interno della repository GitHub sotto la folder reports

****Consegna del dataset post-ingestion**: Se il dataset finale supera i limiti di GitHub (es. >80MB per file o >1GB totali) sarÃ  necessario utilizzare il link che vi verrÃ² passato **privatavamente** al quale caricare il file.

---

## ğŸ“œ Metriche di Valutazione e Punteggi

Passiamo alla valutazione della vostra soluzione che avverrÃ  attraverso cinque macro-criteri. 

Ogni aspetto tiene conto non solo della qualitÃ  tecnica, ma anche della creativitÃ , dellâ€™efficacia dellâ€™analisi e della chiarezza nella comunicazione dei risultati. 
Di seguito la griglia di valutazione dettagliata, il punteggio massimo raggiungibile Ã¨ di **100**:

| Macro-metrica                        | Punteggio massimo | Dettaglio                                                                 |
|-------------------------------------|-------------------|--------------------------------------------------------------------------|
| 1. QualitÃ  della soluzione          | 30 pts            | Codice pulito e documentato, automazione, modularitÃ , riusabilitÃ                       |
| 2. CreativitÃ  della soluzione       | 20 pts            | Idee originali, approcci inediti, uso creativo di tool/LLM              |
| 3. Completezza del dato             | 20 pts            | Aderenza allo schema, qualitÃ  e copertura dei dati                      |
| 4. Efficacia dellâ€™analisi di sentiment | 15 pts         | Accuratezza, rilevanza, originalitÃ  delle intuizioni                    |
| 5. Output e comunicazione (report, grafici, doc) | 15 pts | Chiarezza, presentazione, comprensibilitÃ  per non esperti               |

---

## 1ï¸âƒ£ Inizializzazione progetto 

Ogni team deve creare una propria repository GitHub a partire da un template ufficiale fornito dallâ€™organizzazione. Tutti i team lavoreranno sulla stessa struttura di base per garantire ordine, coerenza e facilitÃ  di valutazione.

### ğŸš€ Istruzioni per iniziare con il template

Per partecipare allâ€™hackathon, ogni team dovrÃ  creare repository su GitHub a cui sarÃ  adattato il template della competizione, segui questi passaggi per iniziare a lavorare:

1. **Creare la repository personale su GitHub**

   Crea una nuova repository pubblica su un profilo GitHub di riferimento per il team, quindi clona la tua nuova repository in locale e posizionati nella root della stessa.
   
2. **Installare copier**

    copier Ã¨ lo strumento che ti permette di generare la struttura di progetto dal template. Va quindi installato usando pip:

      ```bash
   pip install copier
      ```
3. **Importare il template**

    Allâ€™interno della cartella del progetto (dove hai clonato la repo), esegui il seguente comando:

    ```bash
    copier copy gh:lezzco/sentiment-analysis-hackathon-2025 .
    ```
    Una volta completato avrete il template installato, nelle varie folder esistono dei README.md che vi aiuterrano ad orientarvi (se questa guida principale vi sembra troppo confusionaria)
   
**Adesso avete questo template sulla vostra repository e potete iniziare!**

---
## Altre Info:
- I gruppi dovranno essere composti da almeno 2 persone e massimo 4 persone;
- Il premio finale per il gruppo vincitore sarÃ  un buono Amazon dal valore di 400 euro.
  
## ğŸ•’ Timeline

| Evento                            | Data e Ora                      |
|----------------------------------|----------------------------------|
| â³ **Chiusura iscrizioni**        | ğŸ—“ï¸ VenerdÃ¬ 23 maggio, ore 20:45     |
| ğŸ“¤ **Consegna progetto**          | ğŸ—“ï¸ LunedÃ¬ 26 maggio, ore 21:30      |
| ğŸ¤ **Presentazione risultati**    | ğŸ—“ï¸ MartedÃ¬ 27 maggio, ore 08:30      |

