# ğŸ§  Hackathon Big Data & AI  
## Challenge Ufficiale ğŸš€  
**"F1 Social Analytics Engine: estrazione, integrazione e sentiment analysis dal GP di Monaco 2025"**

---
## Indice

- [Obiettivo ğŸ](#obiettivo-)
- [ğŸ“¥ Fase 1 â€” Data Ingestion and Dataset Building](#fase-1---data-ingestion-and-dataset-building)
    - [1.1 Schema dataset finale](#1-.-1-schema-dataset-finale)
- [ğŸ“¥ Fase 2 â€” Sentiment Analysis](#fase-2---sentiment-analysis)
    - [ğŸ¯ Obiettivo della parte di Sentiment Analysis](#obiettivo-della-parte-di-sentiment-analysis)
    - [âœ¨ Bonus: Estensione LLM-based - Creazione automatica dei report](#bonus-estensione-llm-based---generatione-automatica-dei-report)
- [ğŸ“¦ Cosa Consegnare](#cosa-consegnare)
- [ğŸ“œ Metriche di Valutazione e Punteggi](#-metriche-di-valutazione-e-punteggi)
- [1ï¸âƒ£ Inizializzazione progetto](#1-inizializzazione-progetto)
- [ğŸ•’ Timeline](#-timeline)

---

## Obiettivo ğŸ 

In occasione del Gran Premio di Monaco 2025, uno degli eventi piÃ¹ iconici e seguiti della Formula 1, il vostro compito Ã¨ progettare e realizzare un sistema intelligente che recupera, integra e analizza post e commenti provenienti dai social media, per comprendere come gli utenti vivono lâ€™evento prima, durante e dopo la gara, con un focus particolare sul sentiment e sulla geolocalizzazione.

L'obiettivo Ã¨ cogliere le emozioni, le opinioni e le reazioni degli appassionati di motori sparsi in tutto il mondo, offrendo un quadro dinamico e aggiornato in tempo reale su come il pubblico percepisce i piloti, le scuderie, i momenti salienti e gli episodi controversi della gara.

Questa sfida ha due anime principali:

- **Data ingestion & dataset building (fondamentale!)**
- **Sentiment analysis avanzata (con o senza LLM)**

---


## Fase 1 - Data Ingestion and Dataset Building

Progettare e implementare una pipeline di data ingestion che:

- ğŸ” Recupera in modo automatico (o semi-automatico) contenuti testuali da diversi social media (es. Instagram, Facebook, Twitter/X, Reddit, YouTubeâ€¦).

- ğŸ§¹ Pulisce, filtra e normalizza i dati testuali, le interazioni e i metadati.

- ğŸ“¦ Produce un dataset finale conforme a uno schema comune condiviso da tutti i gruppi (vedi sotto).

### NOTE:
- Non devono essere inclusi dati personali identificabili  
- Non violare i ToS dei social: scraping etico o dataset giÃ  disponibili

---

### 1.1 Schema dataset finale:

| Feature           | Descrizione                                                                 | Datatype             | Nullable | Note                                        | Esempio                  |
|-------------------|-----------------------------------------------------------------------------|----------------------|----------|---------------------------------------------|--------------------------|
| content_id        | ID univoco del post o commento                                              | stringa              | No       | es. ID nativo social o hash generato        | fb_post_001              |
| observation_time  | Timestamp di unâ€™osservazione di uno specifico contenuto                     | datetime (ISO 8601)  | No       | formato: YYYY-MM-DDTHH:MM:SSZ                | 2025-05-15T10:00:00Z     |
| user              | ID o nome utente (anonimizzato se necessario)                              | stringa              | No       |                                             | giulia_snap              |
| user_location     | CittÃ /Stato indicati nel profilo dellâ€™utente (se presente)                  | stringa              | Si       |                                             | Nizza                    |
| social_media      | Nome della piattaforma (es. Twitter, Reddit, etc.)                          | stringa              | No       |                                             | Instagram                |
| publish_date      | Timestamp UTC del post/commento                                             | datetime (ISO 8601)  | No       | formato: YYYY-MM-DDTHH:MM:SSZ                | 2025-05-25T19:45:10Z     |
| geo_location      | Coordinate GPS (latitudine, longitudine) del luogo dellâ€™interazione         | tuple(float, float)  | Si       |                                             | (45.4642, 9.1900)        |
| comment_raw_text  | Testo originale del contenuto                                               | stringa              | No       | Se non câ€™Ã¨ testo, mettere stringa vuota ""  | Corsa Pazzesca ğŸ˜¬ğŸï¸       |
| emoji             | Emoji utilizzate nel testo                                                  | Lista[stringa]       | Si       |                                             | ğŸ˜¬ğŸï¸                      |
| reference_post_url| Link al post originale (se Ã¨ una risposta/commento)                        | stringa              | Si       | Deve essere un URL                           | facebook.com/post/123456789 |
| like_count        | Numero di like/upvote                                                       | Intero               | No       | Default 0, non puÃ² essere negativo          | 112                      |
| reply_count       | Numero di commenti/risposte ricevute                                       | Intero               | No       | Default 0, non puÃ² essere negativo          | 17                       |
| repost_count      | Numero di condivisioni/retweet                                             | Intero               | No       | Default 0, non puÃ² essere negativo          | 1                        |
| quote_count       | Quote tweet o repost con commento (se disponibile)                         | Intero               | No       | Default 0, non puÃ² essere negativo          | 0                        |
| bookmark_count    | Numero di salvataggi (se disponibile)                                     | Intero               | No       | Default 0, non puÃ² essere negativo          | 0                        |
| content_type      | Tipo di contenuto analizzato                                               | stringa              | No       | Valore categorico: "post" o "commento"      | post                     |

---

## Fase 2 - Sentiment Analysis

Una volta creato un dataset coerente, la sfida si sposta sull'analisi del sentiment. Ecco cosa includere, come strutturare la consegna e cosa valutare.

### Obiettivo della parte di Sentiment Analysis

Analizzare i contenuti raccolti (post/commenti) per comprendere come evolve lâ€™umore e la percezione degli utenti nel tempo e nello spazio in relazione al Gran Premio di Monaco 2025, con un focus sulle fasi prima, durante e dopo la gara.

Lâ€™analisi puÃ² mettere in luce emozioni, attese, reazioni e controversie legate ai piloti, ai team e possibili correlazioni con gli eventi chiave della gara.

---

### âš™ï¸ Approcci suggeriti

#### 1. Approccio classico (NLP tradizionale)

Utilizzo di tecniche di Natural Language Processing tradizionali, quali:  
- Pre-elaborazione del testo (tokenizzazione, rimozione stopwords, stemming)  
- Rappresentazione con tecniche tipo TF-IDF  
- Classificatori supervisionati (SVM, Naive Bayes, Random Forest)  
- Analizzatori di sentiment giÃ  pronti come TextBlob o VAD  

#### 2. Approccio con LLM (Large Language Models)

Sfruttare modelli linguistici di nuova generazione (GPT, LLaMA, Claude, Mistral, ecc.) per:  
- Classificare direttamente il sentiment di ogni contenuto  
- Estendere lâ€™analisi con rilevazione di emozioni, argomenti principali, intensitÃ  del sentimento  
- Arricchire dati mancanti (es. dedurre location, riconoscere sarcasmo, ecc.)  

Questi modelli possono essere interrogati tramite prompt ben costruiti per analisi dettagliate su testi brevi, rumorosi o ambigui.

---

### Bonus: Estensione LLM-based - Generatione automatica dei report

Oltre alla classificazione del sentiment, Ã¨ incoraggiato lâ€™uso di LLM e modelli multimodali per:  

- ğŸ“Š Generare automaticamente grafici o visualizzazioni dai dati analizzati  
- ğŸ§  Riassumere in linguaggio naturale i risultati (es. "Nei commenti dalla Francia, il sentiment era positivo prima della gara, ma Ã¨ calato dopo lâ€™incidente al 35Â° giro")  

Esempi di strumenti/approcci:  
- GPT-4-Vision, Gemini, Claude 3 per generare visualizzazioni via prompt  
- Plotly + LLM per generare codice Python per grafici  
- Diagrammi, mappe e infografiche sintetiche generate da modelli come DALLÂ·E o Midjourney 


**âš ï¸ Questa parte Ã¨ opzionale ma valorizzata nella valutazione, dimostrando originalitÃ  e padronanza delle tecnologie LLM.**

---

## Cosa Consegnare

Lista degli artefatti da consegnare:

- Codice sorgente su Repository GitHub (link da condividere con gli organizzatori prima della scadenza)
- Dataset generato dallâ€™ingestion (**)
- Report PDF con risultati analisi del sentiment dellâ€™evento (inclusi eventuali grafici Bonus) allâ€™interno della repository GitHub sotto la folder reports

 ğŸ“¥ **Consegna dei dataset post-ingestion**

Se il dataset finale supera i limiti di GitHub (es. >80MB per file o >1GB totali) sarÃ  necessario utilizzare il link che vi verrÃ² passato **privatavamente** al quale caricare il file.

---

## 1ï¸âƒ£ Inizializzazione progetto

Ogni team deve creare una propria repository GitHub a partire da un template ufficiale fornito dallâ€™organizzazione. Tutti i team lavoreranno sulla stessa struttura di base per garantire ordine, coerenza e facilitÃ  di valutazione.

### ğŸš€ Come iniziare

Installare copier (solo la prima volta):

```bash
pip install copier
```




## ğŸ“œ Metriche di Valutazione e Punteggi

La vostra soluzione verrÃ  valutata secondo cinque macro-criteri. Ogni aspetto tiene conto non solo della qualitÃ  tecnica, ma anche della creativitÃ , dellâ€™efficacia dellâ€™analisi e della chiarezza nella comunicazione dei risultati. Di seguito la griglia di valutazione dettagliata:

| Macro-metrica                        | Punteggio massimo | Dettaglio                                                                 |
|-------------------------------------|-------------------|--------------------------------------------------------------------------|
| 1. QualitÃ  della soluzione          | 30 pts            | Codice pulito, automazione, modularitÃ , riusabilitÃ                       |
| 2. CreativitÃ  della soluzione       | 20 pts            | Idee originali, approcci inediti, uso creativo di tool/LLM              |
| 3. Completezza del dato             | 20 pts            | Aderenza allo schema, qualitÃ  e copertura dei dati                      |
| 4. Efficacia dellâ€™analisi di sentiment | 15 pts         | Accuratezza, rilevanza, originalitÃ  delle intuizioni                    |
| 5. Output e comunicazione (report, grafici, doc) | 15 pts | Chiarezza, presentazione, comprensibilitÃ  per non esperti               |


## ğŸ•’ Timeline

| Evento                            | Data e Ora                      |
|----------------------------------|----------------------------------|
| â³ **Chiusura iscrizioni**        | ğŸ—“ï¸ VenerdÃ¬ 23 maggio, ore 20:45     |
| ğŸ“¤ **Consegna progetto**          | ğŸ—“ï¸ LunedÃ¬ 26 maggio, ore 21:30      |
| ğŸ¤ **Presentazione risultati**    | ğŸ—“ï¸ MartedÃ¬ 27 maggio, ore 08:30      |

